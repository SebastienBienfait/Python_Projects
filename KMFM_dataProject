{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Exploration gathering_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastienBienfait/L2C-Data-managment/blob/main/Data_Exploration_gathering_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring data sets\n",
        "---\n",
        "##Gathering the Data"
      ],
      "metadata": {
        "id": "bGQ4E0gGX-PI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my data project I have always wanted to be able to use information taken directly from websites in data analysis. So I taught myself to webscrape using the BeautifulSoup library. As an example of an online data source, I chose KMFM radio because they display in a list all the songs played during each hour of the day. In addition, the url query to load up each seperate day/hour is very intuitive and is easy to formulate based on a for loop.\n",
        "\n",
        "\n",
        "By pressing F12 on a website, you can directly inspect much of the html code that is used to genereate the site. By visually inspecting the html on the website we can see which classes and tags are used to define the information we need. Importing the html using BeautifulSoup we can explore the code using .find() and .find_all() methods to search out the markers and extract the information within them, including text strings and other urls. \n",
        "\n",
        "Thanks to the way all the information was layed out on the KMFM site, once collected, all the information fitted neatly into a Pandas dataframe ready to be cleaned and analysed."
      ],
      "metadata": {
        "id": "W7zEZVRsTdBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data collected here is raw data from the KMFM radio website, [https://www.kmfm.co.uk/played](https://www.kmfm.co.uk/played).\n",
        "\n",
        "This data is cleaned and analysed in the following file: https://github.com/SebastienBienfait/L2C-Data-managment/blob/main/Data_Exploration_use_data.ipynb\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "N--DXoRiSmZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing libraries I have used  \n",
        "BeautifulSoup is the library used for the web html filtering.  \n",
        "Requests library is used to obtain the html from the required site."
      ],
      "metadata": {
        "id": "7G3pgO-Tc7EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "url = \"https://www.kmfm.co.uk/played/?date=2022-04-28&hour=14\""
      ],
      "metadata": {
        "id": "pXoRnCCDqge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function imports the html of a site and converts it to a usable formate using BeautifulSoup."
      ],
      "metadata": {
        "id": "mO8WKWmhR8TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_html(url): #this returns all the html of the requested website from which information can be extracted\n",
        "  page = requests.get(url)\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  return soup\n",
        "  \n",
        "def convert_datetime(time_str,input,output):\n",
        "  if time_str == None:\n",
        "    return float(\"nan\")\n",
        "\n",
        "  date_form = datetime.strptime(time_str,input)\n",
        "  time_played = datetime.strftime(date_form, output)\n",
        "  return time_played"
      ],
      "metadata": {
        "id": "h7KUjxHR4pCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YC1pCXRscDOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Secondary webscraping funtion\n",
        "This function receives the Itunes link of the song which then scapes the year of publication and the song genre  \n",
        "\n",
        "This finds additional information on each song from a second url that is scraped from the first site. The second site (Itunes) was much less structured in how they presented their data leading to null/missing information on several songs."
      ],
      "metadata": {
        "id": "ZPIN30hJ4zO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_genre_and_age(url): #\n",
        "  try:\n",
        "    if url == None: #if the Itunes link was not on the site then 'nan' is returned for both values\n",
        "      return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    elif url != None:\n",
        "      soup = get_html(url)\n",
        "\n",
        "      song_info = soup.find(class_=\"product-meta typography-callout-emphasized\").text.strip()\n",
        "      song_genre = song_info.split(\"·\")[0]\n",
        "\n",
        "      song_age_str = song_info.split(\"·\")[1].strip()\n",
        "      song_age = convert_datetime(song_age_str,\"%Y\",\"%Y\")\n",
        "      return song_age, song_genre\n",
        "  except: \n",
        "    return float(\"nan\"), float(\"nan\") #if any unexpected errors occur during the scraping and string comprehesion (wrong/diffenert information returned) 'nan' is also retured\n"
      ],
      "metadata": {
        "id": "_FaZF0SZ4oJ2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###This is the main webscraping funtion\n",
        "This returns the song name, artist(s) name(s), genre, publishing year, time played at and the DJ's name "
      ],
      "metadata": {
        "id": "Pp4Xy4WI4304"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omq5otEAX7z8"
      },
      "outputs": [],
      "source": [
        "def find_songs(url):\n",
        "  results = url.find(class_=\"s-page\") # class: \"s-page\" contained the main block of information of the site, ignoring the headers, ads ect... \n",
        "                                      # I called this so that the .find_all would not have to querey the entire block of html, just the smaller relevent section.\n",
        "  tracks_played = results.find_all(class_=\"gm-sec-text\") # class:\"gm-sec-text\" is the info box of each song and all the relevent information on the KMFM site itself is here.\n",
        "  \n",
        "  track_list = []\n",
        "  for track in tracks_played:\n",
        "\n",
        "    itunes_url = track.find(\"a\",class_ = \"icon icon-download\") #this finds the Itunes link for each song played that hour\n",
        "    if itunes_url != None: #if an Itunes link is not available for that song it returns 'None'\n",
        "      Itunes_link = itunes_url[\"href\"]\n",
        "    else:\n",
        "      Itunes_link = None\n",
        "   \n",
        "    song_age, song_genre = get_genre_and_age(Itunes_link) #sends the Itunes link for each song to be scaped and relevent info to be returned\n",
        "\n",
        "\n",
        "    #at the top of each page the title of the show is displayed and by which DJ, from this I attempted to extract the DJ's name for the database\n",
        "    try: #an exception was needed here as there were many different errors as differnet sentence structure was used in a few minor cases\n",
        "      dj_name = results.find(\"h2\").text.strip().split(\"with \",1)[1].replace(\")\",\"\") #This finds the DJ name(s) from the \"What we played\" string and strips all but the DJ name from it. ####\"Temp\"#####\n",
        "    except:\n",
        "      dj_name = float(\"nan\")\n",
        "    song_name = track.find(\"p\", class_=\"gm-sec-title\").text.strip() #This finds the song name from the first <a class=\"gm-sec-title\">.\n",
        "    artist_name = track.find(\"a\").text.strip() #This stips the artist name from the url link <a href=\"/artist/\"> which is under the second <a class=\"gm-sec-title\">.\n",
        "    time_str = track.find(\"p\", class_=\"gm-sec-meta\").text.strip() #This strips the time played from the <a class=\"gm-sec-meta\"> at the top, then converts it into 24hr datetime format below.\n",
        "    time_played = convert_datetime(time_str,\"%I:%M%p\",\"%H:%M\")\n",
        "      \n",
        "    track_info = [song_name, artist_name, song_genre, song_age, time_played, dj_name]\n",
        "    track_list.append(track_info)\n",
        "\n",
        "  return track_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The site used only showed the songs played for 1 hour per page, to obtain information about the whole day, the url for each hour in the day must be used.\n",
        "\n",
        "This function calls the main webscaping function using a generated querey made from the date code, a list of hours and the base url of the site.  \n",
        "This is then sent to be scaped and have its data extracted.\n",
        "\n",
        "\n",
        "WARNING: This function take almost an hour to run. Also the current datecodes no longer funtion as information is only stored on the KMFM site for up to 1 week."
      ],
      "metadata": {
        "id": "BNBkuugVq1le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate_over_day(daycode):\n",
        "  df_songs = pd.DataFrame(columns=[\"song_name\", \"artist_name\", \"song_genre\", \"publish_year\", \"time_played_at\", \"dj_name\"]) #creating the empty df with requisit column names\n",
        "  base_url = \"https://www.kmfm.co.uk/played/\" \n",
        "  day_querey = \"?date=\"+ daycode #the date portion of the querey\n",
        "  actual_querey = \"https://www.kmfm.co.uk/played/?date=2022-04-27&hour=04\" #example of actualy querey, used for testing\n",
        "\n",
        "  hours_list = [\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"] #list of every hour that KMFM radio plays during the day\n",
        "\n",
        "  for hour in hours_list:\n",
        "    hour_querey = \"&hour=\" + hour #the hour portion of the querey\n",
        "    final_url = base_url + day_querey + hour_querey #the full url from which the html is requsted from\n",
        "\n",
        "    site_html = get_html(final_url) #sends the request for the html using the url created previousely\n",
        "\n",
        "    data = find_songs(site_html) #extracts the relevent information from bulk html\n",
        "\n",
        "    temp_df = pd.DataFrame(data, columns=[\"song_name\", \"artist_name\", \"song_genre\", \"publish_year\", \"time_played_at\", \"dj_name\"])\n",
        "    #temp_df hold the information for each hour \n",
        "\n",
        "\n",
        "    df_songs = pd.concat([df_songs,temp_df], ignore_index=True) #appends the data from that hour into the final database each loop\n",
        "\n",
        "  filename = \"kmfm_songs_\" + daycode + \".csv\"\n",
        "  df_songs.to_csv(filename) #saving the df as a .csv file to be used analysed\n",
        "  return df_songs\n",
        "\n",
        "df_songs_played_27 = iterate_over_day(\"2022-04-27\") #thur\n",
        "df_songs_played_26 = iterate_over_day(\"2022-04-26\") #fri\n",
        "df_songs_played_25 = iterate_over_day(\"2022-04-25\") #sat\n",
        "df_songs_played_24 = iterate_over_day(\"2022-04-24\") #sun\n",
        "df_songs_played_23 = iterate_over_day(\"2022-04-23\") #mon\n",
        "df_songs_played_22 = iterate_over_day(\"2022-04-22\") #tue\n",
        "df_songs_played_21 = iterate_over_day(\"2022-04-21\") #wed\n",
        "#each of these data frames now holds full information of every song played during a day"
      ],
      "metadata": {
        "id": "Lk_QBePiq0Z_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
